{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The script uses Berkeley Neural Parser to parse the generated instructions, and visualize the results using Plotly.\n",
    "\n",
    "Please make sure to install benepar following their documentation [here](https://github.com/nikitakit/self-attentive-parser#installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP\\self-instruct-learning\\self_instruct\\instruction_visualize.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbenepar\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_md\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39m\u001b[39mThe time for action is now. It\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms never too late to do something.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m spacy\u001b[39m.\u001b[39m__version__\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\irvin\\.conda\\envs\\NLP\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\irvin\\.conda\\envs\\NLP\\lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import benepar, spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(\"The time for action is now. It's never too late to do something.\")\n",
    "\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP\\self-instruct-learning\\self_instruct\\instruction_visualize.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     first_sent \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(doc\u001b[39m.\u001b[39msents)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find_root_verb_and_its_dobj(first_sent\u001b[39m.\u001b[39mroot)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m find_root_verb_and_its_dobj_in_string(\u001b[39m\"\u001b[39;49m\u001b[39mWrite me a story about education.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32md:\\NLP\\self-instruct-learning\\self_instruct\\instruction_visualize.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_root_verb_and_its_dobj_in_string\u001b[39m(s):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(s)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     first_sent \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(doc\u001b[39m.\u001b[39msents)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find_root_verb_and_its_dobj(first_sent\u001b[39m.\u001b[39mroot)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "def find_root_verb_and_its_dobj(tree_root):\n",
    "    # first check if the current node and its children satisfy the condition\n",
    "    if tree_root.pos_ == \"VERB\":\n",
    "        for child in tree_root.children:\n",
    "            if child.dep_ == \"dobj\" and child.pos_ == \"NOUN\":\n",
    "                return tree_root.lemma_, child.lemma_\n",
    "        return tree_root.lemma_, None\n",
    "    # if not, check its children\n",
    "    for child in tree_root.children:\n",
    "        return find_root_verb_and_its_dobj(child)\n",
    "    # if no children satisfy the condition, return None\n",
    "    return None, None\n",
    "\n",
    "def find_root_verb_and_its_dobj_in_string(s):\n",
    "    doc = nlp(s)\n",
    "    first_sent = list(doc.sents)[0]\n",
    "    return find_root_verb_and_its_dobj(first_sent.root)\n",
    "\n",
    "find_root_verb_and_its_dobj_in_string(\"Write me a story about education.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_modified_open() missing 1 required positional argument: 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP\\self-instruct-learning\\self_instruct\\instruction_visualize.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m generated_data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/gpt3_generations/machine_generated_instructions.jsonl\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# replace this with your own data path\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m machine_generated_tasks \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m() \u001b[39mas\u001b[39;00m fin:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m fin:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/self-instruct-learning/self_instruct/instruction_visualize.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         machine_generated_tasks\u001b[39m.\u001b[39mappend(json\u001b[39m.\u001b[39mloads(line))\n",
      "\u001b[1;31mTypeError\u001b[0m: _modified_open() missing 1 required positional argument: 'file'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "generated_data_path = \"data/gpt3_generations/machine_generated_instructions.jsonl\" # replace this with your own data path\n",
    "machine_generated_tasks = []\n",
    "with open() as fin:\n",
    "    for line in fin:\n",
    "        machine_generated_tasks.append(json.loads(line))\n",
    "\n",
    "instructions = set([task[\"instruction\"] for task in machine_generated_tasks])\n",
    "print(len(instructions))\n",
    "\n",
    "raw_phrases = []\n",
    "for instruction in tqdm.tqdm(instructions):\n",
    "    try:\n",
    "        verb, noun = find_root_verb_and_its_dobj_in_string(instruction)\n",
    "        raw_phrases.append({\n",
    "            \"verb\": verb,\n",
    "            \"noun\": noun,\n",
    "            \"instruction\": instruction\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_phrases = pd.DataFrame(raw_phrases)\n",
    "phrases = pd.DataFrame(raw_phrases).dropna()\n",
    "phrases[[\"verb\", \"noun\"]].groupby([\"verb\", \"noun\"]).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_verbs = phrases[[\"verb\"]].groupby([\"verb\"]).size().nlargest(20).reset_index()\n",
    "\n",
    "df = phrases[phrases[\"verb\"].isin(top_verbs[\"verb\"].tolist())]\n",
    "# df = df[~df[\"noun\"].isin([\"I\", \"what\"])]\n",
    "# df = phrases\n",
    "# df[~df[\"verb\"].isin(top_verbs[\"verb\"].tolist())][\"verb\"] = \"other\"\n",
    "# df[~df[\"verb\"].isin(top_verbs[\"verb\"].tolist())][\"noun\"] = \"other\"\n",
    "df = df.groupby([\"verb\", \"noun\"]).size().reset_index().rename(columns={0: \"count\"}).sort_values(by=[\"count\"], ascending=False)\n",
    "# df = df[df[\"count\"] > 10]\n",
    "df = df.groupby(\"verb\").apply(lambda x: x.sort_values(\"count\", ascending=False).head(4)).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "machine_generated_tasks = []\n",
    "with open(\"data/batch_221120_combined/clean_data_wo_human.jsonl\") as fin:\n",
    "    for line in fin:\n",
    "        machine_generated_tasks.append(json.loads(line))\n",
    "\n",
    "instructions = set([task[\"instruction\"] for task in machine_generated_tasks])\n",
    "print(len(instructions))\n",
    "\n",
    "raw_phrases = []\n",
    "for instruction in tqdm.tqdm(instructions):\n",
    "    try:\n",
    "        verb, noun = find_root_verb_and_its_dobj_in_string(instruction)\n",
    "        raw_phrases.append({\n",
    "            \"verb\": verb,\n",
    "            \"noun\": noun,\n",
    "            \"instruction\": instruction\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# df[\"blank\"] = \"ROOT\"\n",
    "# df = phrases.groupby([\"verb\", \"noun\"]).size().sort_values(ascending=False).head(5).reset_index().rename(columns={0: \"count\"})\n",
    "\n",
    "df = df[df[\"count\"] > 30]\n",
    "fig = px.sunburst(df, path=['verb', 'noun'], values='count')\n",
    "# fig.update_layout(uniformtext=dict(minsize=10, mode='hide'))\n",
    "fig.update_layout(\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    font_family=\"Times New Roman\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html(\"output/verb_noun.html\")\n",
    "# fig.savefig(\"output/verb_noun.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
